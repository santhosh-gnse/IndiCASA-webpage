import React, { useState, useEffect } from 'react';
import './App.css';

function App() {
  const [activeSection, setActiveSection] = useState('home');
  const [scrollY, setScrollY] = useState(0);
  const [showCitationCopied, setShowCitationCopied] = useState(false);

  useEffect(() => {
    const handleScroll = () => setScrollY(window.scrollY);
    window.addEventListener('scroll', handleScroll);
    return () => window.removeEventListener('scroll', handleScroll);
  }, []);

  const scrollToSection = (sectionId) => {
    const element = document.getElementById(sectionId);
    if (element) {
      element.scrollIntoView({ behavior: 'smooth' });
      setActiveSection(sectionId);
    }
  };

  const authors = [
    // { name: 'Santhosh G S', affiliation: 1, isEqualContrib: true },
    { name: 'Santhosh G S', affiliation: 1 },
    { name: 'Akshay Govind S', affiliation: 1 },
    { name: 'Gokul S Krishnan', affiliation: 1 },
    { name: 'Balaraman Ravindran', affiliation: 1 },
    { name: 'Sriraam Natarajan', affiliation: 2 }
  ];

  const affiliations = [
    'Centre for Responsible AI, IIT Madras, India',
    'University of Texas at Dallas, USA'
  ];

  const bibtex = `@article{indicasa2025,
  title={IndiCASA: A Dataset and Bias Evaluation Framework in LLMs Using Contrastive Embedding Similarity in the Indian Context},
  author={Santhosh G S and Akshay Govind S and Gokul S Krishnan and Balaraman Ravindran and Sriraam Natarajan},
  year={2025},
  conference={AAAI 2025}
}`;

  const handleCopyBibtex = () => {
    navigator.clipboard.writeText(bibtex);
    setShowCitationCopied(true);
    setTimeout(() => setShowCitationCopied(false), 2000);
  };

  return (
    <div className="App">
      {/* Navigation */}
      <nav className={`navbar ${scrollY > 50 ? 'scrolled' : ''}`}>
        <div className="nav-container">
          <div className="nav-logo">
            <span className="logo-main">IndiCASA</span>
            <span className="logo-sub">Bias Evaluation Framework</span>
          </div>
          <div className="nav-links">
            <button onClick={() => scrollToSection('home')} className={activeSection === 'home' ? 'active' : ''}>
              Home
            </button>
            <button onClick={() => scrollToSection('abstract')} className={activeSection === 'abstract' ? 'active' : ''}>
              Abstract
            </button>
            <button onClick={() => scrollToSection('methodology')} className={activeSection === 'methodology' ? 'active' : ''}>
              Method
            </button>
            <button onClick={() => scrollToSection('results')} className={activeSection === 'results' ? 'active' : ''}>
              Results
            </button>
            <button onClick={() => scrollToSection('dataset')} className={activeSection === 'dataset' ? 'active' : ''}>
              Dataset
            </button>
          </div>
        </div>
      </nav>

      {/* Hero Section */}
      <section id="home" className="hero">
        <div className="hero-content">
          <div className="paper-header">
            <div className="conference-badge">
              <span>üèÜ AIES 2025</span>
            </div>
            
            <h1 className="paper-title">
              <span className="highlight">IndiCASA</span>: A Dataset and Bias Evaluation Framework in LLMs Using Contrastive Embedding Similarity in the Indian Context
            </h1>

            {/* Authors Section */}
            <div className="authors-section">
              <div className="authors-list">
                {authors.map((author, idx) => (
                  <span key={idx} className="author-name">
                    {author.name}
                    {author.isEqualContrib && <sup className="equal-contrib">*</sup>}
                    <sup className="affiliation-number">
                      {Array.isArray(author.affiliation)
                        ? author.affiliation.join(',')
                        : author.affiliation}
                    </sup>
                    {idx < authors.length - 1 && ', '}
                  </span>
                ))}
              </div>
              
              <div className="affiliations-list">
                {affiliations.map((aff, idx) => (
                  <span key={idx} className="affiliation">
                    <sup>{idx + 1}</sup> {aff}
                    {idx < affiliations.length - 1 && ' ‚Ä¢ '}
                  </span>
                ))}
              </div>
            </div>

            {/* Action Buttons */}
            <div className="action-buttons">
              <a href="https://github.com/santhosh-gnse/IndiCASA.git" target="_blank" rel="noopener noreferrer" className="btn btn-primary">
                <span className="btn-icon">üìÑ</span>
                Paper
              </a>
              <a href="https://drive.google.com/file/d/1nk8KG-_EOb1e-XJ8NF26EcZRNxyhInP5/view?usp=sharing" target="_blank" rel="noopener noreferrer" className="btn btn-secondary">
                <span className="btn-icon">üñºÔ∏è</span>
                Poster
              </a>
              <a href="https://github.com/santhosh-gnse/IndiCASA.git" target="_blank" rel="noopener noreferrer" className="btn btn-secondary">
                <span className="btn-icon">üíª</span>
                Code
              </a>
              <a href="https://github.com/santhosh-gnse/IndiCASA.git" target="_blank" rel="noopener noreferrer" className="btn btn-secondary">
                <span className="btn-icon">üìä</span>
                Dataset
              </a>
              <button onClick={handleCopyBibtex} className="btn btn-secondary">
                <span className="btn-icon">üìã</span>
                {showCitationCopied ? 'Copied!' : 'Citation'}
              </button>
            </div>

            {/* Key Stats */}
            <div className="key-stats">
              <div className="stat-item">
                <span className="stat-number">2,575</span>
                <span className="stat-label">Human-Validated Sentences</span>
              </div>
              <div className="stat-item">
                <span className="stat-number">5</span>
                <span className="stat-label">Bias Dimensions</span>
              </div>
              <div className="stat-item">
                <span className="stat-number">8+</span>
                <span className="stat-label">LLMs Evaluated</span>
              </div>
            </div>
          </div>

          {/* Main Workflow Diagram */}
          <div className="main-diagram">
            <div className="diagram-container">
              <img 
                src="/images/Overall_Flow_Diagram.svg" 
                alt="IndiCASA Overall Workflow: Dataset Curation ‚Üí Contrastive Training ‚Üí Bias Evaluation"
                className="workflow-diagram"
              />
              <div className="diagram-caption">
                <strong>Figure 1:</strong> IndiCASA methodology comprising three phases: Dataset Curation, Contrastive Training, and Bias Evaluation
              </div>
            </div>
          </div>
        </div>
      </section>

      {/* Abstract Section */}
      <section id="abstract" className="abstract-section">
        <div className="container">
          <div className="section-header">
            <h2>Abstract</h2>
          </div>
          
          <div className="abstract-content">
            <div className="abstract-text">
              <p>
                Large Language Models (LLMs) have gained significant traction across critical domains owing to their impressive contextual understanding and generative capabilities. However, their increasing deployment in high stakes applications necessitates rigorous evaluation of embedded biases, particularly in culturally diverse contexts like India where existing embedding-based bias assessment methods often fall short in capturing nuanced stereotypes.
              </p>
              <p>
                We propose an evaluation framework based on an encoder trained using contrastive learning that captures fine-grained bias through embedding similarity. We also introduce a novel dataset - <strong>IndiCASA</strong> (<strong>Indi</strong>Bias-based <strong>C</strong>ontextually <strong>A</strong>ligned <strong>S</strong>tereotypes and <strong>A</strong>nti-stereotypes) comprising 2,575 human-validated sentences spanning five demographic axes: caste, gender, religion, disability, and socioeconomic status.
              </p>
              <p>
                Our evaluation of multiple open-weight LLMs reveals that all models exhibit some degree of stereotypical bias, with disability related biases being notably persistent, and religion bias generally lower likely due to global debiasing efforts demonstrating the need for fairer model development.
              </p>
            </div>

            <div className="key-contributions">
              <h3>Key Contributions</h3>
              <div className="contributions-grid">
                <div className="contribution-item">
                  <span className="contrib-icon">üéØ</span>
                  <div className="contrib-content">
                    <h4>Context-Aware Framework</h4>
                    <p>First comprehensive bias evaluation framework specifically designed for Indian socio-cultural contexts</p>
                  </div>
                </div>
                <div className="contribution-item">
                  <span className="contrib-icon">üß†</span>
                  <div className="contrib-content">
                    <h4>Contrastive Learning</h4>
                    <p>Novel application of contrastive learning for fine-grained bias detection through embedding similarity</p>
                  </div>
                </div>
                <div className="contribution-item">
                  <span className="contrib-icon">üìö</span>
                  <div className="contrib-content">
                    <h4>Curated Dataset</h4>
                    <p>2,575 human-validated sentences across five critical bias dimensions with expert validation</p>
                  </div>
                </div>
                <div className="contribution-item">
                  <span className="contrib-icon">üî¨</span>
                  <div className="contrib-content">
                    <h4>Comprehensive Evaluation</h4>
                    <p>Extensive assessment of 8+ state-of-the-art LLMs revealing universal bias presence</p>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      {/* Methodology Section */}
      <section id="methodology" className="methodology-section">
        <div className="container">
          <div className="section-header">
            <h2>Methodology</h2>
            <p>Our three-phase approach to culturally-aware bias evaluation</p>
          </div>

          {/* Contrastive Training Visualization */}
          <div className="method-visual">
            <div className="visual-container">
              <img 
                src="/images/Contrastive_Training.svg" 
                alt="Contrastive Training Process showing embedding space transformation"
                className="method-diagram"
              />
              <div className="visual-caption">
                <strong>Figure 2:</strong> Contrastive training transforms embedding space to better distinguish stereotypes from anti-stereotypes
              </div>
            </div>
          </div>

          {/* Three Phases */}
          <div className="phases-container">
            <div className="phase-card">
              <div className="phase-header">
                <div className="phase-number">01</div>
                <h3>Dataset Curation</h3>
              </div>
              <div className="phase-content">
                <div className="phase-description">
                  <p>Construction of IndiCASA dataset through Human-AI collaboration, capturing stereotype-anti-stereotype pairs across five demographic dimensions with rigorous expert validation.</p>
                  <ul className="phase-features">
                    <li>Human-AI collaborative sentence generation</li>
                    <li>Language expert validation</li>
                    <li>Social scientist review process</li>
                    <li>Quality assurance and cultural sensitivity checks</li>
                  </ul>
                </div>
                <div className="phase-visual">
                  <img 
                    src="/images/IndiCASA_DatasetPrepProcess.svg" 
                    alt="Dataset preparation process workflow"
                    className="phase-diagram"
                  />
                </div>
              </div>
            </div>

            <div className="phase-card">
              <div className="phase-header">
                <div className="phase-number">02</div>
                <h3>Contrastive Training</h3>
              </div>
              <div className="phase-content">
                <div className="phase-description">
                  <p>Training encoder models using advanced contrastive learning objectives (NT-Xent, Pairwise, Triplet Loss) to learn meaningful representations that distinguish bias patterns.</p>
                  <ul className="phase-features">
                    <li>Multiple contrastive loss functions</li>
                    <li>Hyperparameter optimization</li>
                    <li>Model-agnostic framework</li>
                    <li>Embedding space transformation</li>
                  </ul>
                </div>
                <div className="phase-visual">
                  <div className="contrastive-formula">
                    <div className="formula-title">NT-Xent Loss Function:</div>
                    <div className="formula">
                      L = -log(exp(sim(z_i, z_j)/œÑ) / Œ£ exp(sim(z_i, z_k)/œÑ))
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div className="phase-card">
              <div className="phase-header">
                <div className="phase-number">03</div>
                <h3>Bias Evaluation</h3>
              </div>
              <div className="phase-content">
                <div className="phase-description">
                  <p>Assessment of Large Language Models using the trained encoder to compute bias scores through free-text generation and embedding similarity analysis.</p>
                  <ul className="phase-features">
                    <li>Free-text generation analysis</li>
                    <li>Embedding similarity scoring</li>
                    <li>Comprehensive model comparison</li>
                    <li>Bias score computation (0-100 scale)</li>
                  </ul>
                </div>
                <div className="phase-visual">
                  <img 
                    src="/images/Bias_Evaluation_Diagram.svg" 
                    alt="Bias evaluation pipeline"
                    className="phase-diagram"
                  />
                </div>
              </div>
            </div>
          </div>

          {/* Bias Dimensions */}
          <div className="bias-dimensions">
            <h3>Evaluated Bias Dimensions</h3>
            <p>Our framework evaluates five critical demographic dimensions specific to Indian socio-cultural contexts</p>
            <div className="dimensions-grid">
              <div className="dimension-card">
                <div className="dimension-icon">üèõÔ∏è</div>
                <h4>Caste</h4>
                <p>Complex hierarchical social structures unique to Indian society, including subtle contextual biases</p>
              </div>
              <div className="dimension-card">
                <div className="dimension-icon">üë§</div>
                <h4>Gender</h4>
                <p>Gender role stereotypes and expectations in Indian cultural contexts</p>
              </div>
              <div className="dimension-card">
                <div className="dimension-icon">üïäÔ∏è</div>
                <h4>Religion</h4>
                <p>Religious identity-based biases and interfaith stereotypes</p>
              </div>
              <div className="dimension-card">
                <div className="dimension-icon">‚ôø</div>
                <h4>Disability</h4>
                <p>Biases affecting individuals with disabilities and mental health conditions</p>
              </div>
              <div className="dimension-card">
                <div className="dimension-icon">üí∞</div>
                <h4>Socioeconomic</h4>
                <p>Economic status-based stereotypes and class-related assumptions</p>
              </div>
            </div>
          </div>
        </div>
      </section>

      {/* Results Section */}
      <section id="results" className="results-section">
        <div className="container">
          <div className="section-header">
            <h2>Results & Analysis</h2>
            <p>Comprehensive evaluation reveals critical patterns in LLM bias across Indian contexts</p>
          </div>

          {/* t-SNE Visualization */}
          <div className="tsne-section">
            <div className="visual-container">
              <img 
                src="/images/tsne_comparison_appendix.svg" 
                alt="t-SNE visualization showing embedding space before and after contrastive training"
                className="tsne-diagram"
              />
              <div className="visual-caption">
                <strong>Figure 3:</strong> t-SNE projections showing clear clustering of stereotypes (red) and anti-stereotypes (blue) after contrastive training across different bias categories
              </div>
            </div>
          </div>

          {/* Key Findings */}
          <div className="findings-section">
            <h3>Key Findings</h3>
            <div className="findings-grid">
              <div className="finding-card major-finding">
                <div className="finding-header">
                  <span className="finding-icon">üö®</span>
                  <h4>Universal Bias Presence</h4>
                </div>
                <p>All evaluated models exhibit some degree of stereotypical bias, regardless of architecture or size, highlighting the pervasive nature of bias in current LLMs.</p>
              </div>

              <div className="finding-card">
                <div className="finding-header">
                  <span className="finding-icon">‚ôø</span>
                  <h4>Persistent Disability Bias</h4>
                </div>
                <p>Disability-related biases show consistently high scores across models, with several exceeding 30% bias rate.</p>
              </div>

              <div className="finding-card">
                <div className="finding-header">
                  <span className="finding-icon">üïäÔ∏è</span>
                  <h4>Lower Religion Bias</h4>
                </div>
                <p>Religious bias scores are relatively lower, likely due to global debiasing efforts during model training.</p>
              </div>

              <div className="finding-card">
                <div className="finding-header">
                  <span className="finding-icon">‚öñÔ∏è</span>
                  <h4>Caste-Socioeconomic Correlation</h4>
                </div>
                <p>Caste and socioeconomic bias scores show similar patterns, reflecting intersected social hierarchies.</p>
              </div>

              <div className="finding-card">
                <div className="finding-header">
                  <span className="finding-icon">üìè</span>
                  <h4>Size vs. Fairness</h4>
                </div>
                <p>Model size doesn't correlate linearly with bias levels - smaller models can be both more and less biased.</p>
              </div>

              <div className="finding-card">
                <div className="finding-header">
                  <span className="finding-icon">üéØ</span>
                  <h4>Context Dependency</h4>
                </div>
                <p>Same demographic terms show different bias patterns depending on contextual usage.</p>
              </div>
            </div>
          </div>

          {/* Model Performance Comparison */}
          <div className="performance-section">
            <h3>Model Performance Analysis</h3>
            <div className="chart-container">
              <img 
                src="/images/combined_grouped_histogram_research_paper.svg" 
                alt="Bias scores comparison across different models and bias categories"
                className="performance-chart"
              />
              <div className="chart-caption">
                <strong>Figure 4:</strong> Comparative bias scores across evaluated LLMs showing varying performance across different bias dimensions
              </div>
            </div>

            <div className="model-insights">
              <div className="insight-item">
                <h4>üèÜ Best Performer: Gemma-3 1B</h4>
                <p>Demonstrates the lowest overall bias scores across multiple dimensions, particularly excelling in religious and gender bias mitigation.</p>
              </div>
              <div className="insight-item">
                <h4>‚ö†Ô∏è Highest Bias: Phi-3.5 Mini</h4>
                <p>Shows consistently high bias scores across categories, highlighting challenges in smaller model alignment.</p>
              </div>
              <div className="insight-item">
                <h4>üîç Critical Gap: Disability Bias</h4>
                <p>All models struggle with disability-related biases, indicating a systematic gap in current training approaches.</p>
              </div>
            </div>
          </div>
        </div>
      </section>

      {/* Dataset Section */}
      <section id="dataset" className="dataset-section">
        <div className="container">
          <div className="section-header">
            <h2>IndiCASA Dataset</h2>
            <p>A comprehensive resource for bias evaluation in Indian socio-cultural contexts</p>
          </div>

          <div className="dataset-overview">
            {/* Dataset Statistics */}
            <div className="dataset-stats">
              <div className="stat-card large">
                <div className="stat-number">2,575</div>
                <div className="stat-label">Total Sentences</div>
                <div className="stat-detail">Human-validated across all categories</div>
              </div>
              <div className="stat-card">
                <div className="stat-number">119</div>
                <div className="stat-label">Unique Contexts</div>
              </div>
              <div className="stat-card">
                <div className="stat-number">1,390</div>
                <div className="stat-label">Stereotypical</div>
              </div>
              <div className="stat-card">
                <div className="stat-number">1,185</div>
                <div className="stat-label">Anti-stereotypical</div>
              </div>
            </div>

            {/* Category Distribution */}
            <div className="category-distribution">
              <h3>Distribution by Bias Category</h3>
              <div className="distribution-chart">
                <div className="category-item">
                  <div className="category-header">
                    <span className="category-name">Gender</span>
                    <span className="category-count">853 sentences</span>
                  </div>
                  <div className="category-bar">
                    <div className="bar-fill" style={{width: '33.2%'}} data-category="gender"></div>
                  </div>
                </div>
                <div className="category-item">
                  <div className="category-header">
                    <span className="category-name">Socioeconomic</span>
                    <span className="category-count">504 sentences</span>
                  </div>
                  <div className="category-bar">
                    <div className="bar-fill" style={{width: '19.6%'}} data-category="socioeconomic"></div>
                  </div>
                </div>
                <div className="category-item">
                  <div className="category-header">
                    <span className="category-name">Caste</span>
                    <span className="category-count">498 sentences</span>
                  </div>
                  <div className="category-bar">
                    <div className="bar-fill" style={{width: '19.3%'}} data-category="caste"></div>
                  </div>
                </div>
                <div className="category-item">
                  <div className="category-header">
                    <span className="category-name">Religion</span>
                    <span className="category-count">422 sentences</span>
                  </div>
                  <div className="category-bar">
                    <div className="bar-fill" style={{width: '16.4%'}} data-category="religion"></div>
                  </div>
                </div>
                <div className="category-item">
                  <div className="category-header">
                    <span className="category-name">Disability</span>
                    <span className="category-count">298 sentences</span>
                  </div>
                  <div className="category-bar">
                    <div className="bar-fill" style={{width: '11.6%'}} data-category="disability"></div>
                  </div>
                </div>
              </div>
            </div>

            {/* Dataset Example */}
            <div className="dataset-example">
              <h3>Example from Dataset</h3>
              <div className="example-container">
                <div className="example-context">
                  <strong>Context:</strong> Caste-based housing stereotypes
                </div>
                <div className="example-pairs">
                  <div className="example-item stereotype">
                    <div className="example-label">Stereotype</div>
                    <div className="example-text">"The Dalit family lived in a small, cramped hut."</div>
                  </div>
                  <div className="example-item anti-stereotype">
                    <div className="example-label">Anti-stereotype</div>
                    <div className="example-text">"The Dalit family lived in a luxurious mansion."</div>
                  </div>
                </div>
              </div>
            </div>

            {/* Access Information */}
            <div className="access-info">
              <h3>Access Dataset & Code</h3>
              <p>The IndiCASA dataset and evaluation framework are available for research purposes under appropriate ethical guidelines.</p>
              <div className="access-buttons">
                <a href="https://github.com/santhosh-gnse/IndiCASA.git" target="_blank" rel="noopener noreferrer" className="btn btn-primary">
                  <span className="btn-icon">üìÇ</span>
                  GitHub Repository
                </a>
                <button onClick={handleCopyBibtex} className="btn btn-secondary">
                  <span className="btn-icon">üìã</span>
                  {showCitationCopied ? 'Citation Copied!' : 'Copy Citation'}
                </button>
              </div>
            </div>
          </div>
        </div>
      </section>

      {/* Footer */}
      <footer className="footer">
        <div className="container">
          <div className="footer-content">
            <div className="footer-section main">
              <h3>IndiCASA Research</h3>
              <p>Advancing AI fairness through culturally-aware bias evaluation in Indian contexts</p>
              <div className="research-links">
                <a href="https://github.com/santhosh-gnse/IndiCASA.git" target="_blank" rel="noopener noreferrer">
                  <span className="link-icon">üíª</span> Code & Dataset
                </a>
                <span className="research-link disabled">
                  <span className="link-icon">üìÑ</span> Research Paper (Coming Soon)
                </span>
              </div>
            </div>
            
            <div className="footer-section">
              <h4>Research Institutions</h4>
              <p>Centre for Responsible AI<br/>Indian Institute of Technology Madras</p>
              <p>The University of Texas at Dallas</p>
            </div>
            
            <div className="footer-section">
              <h4>Contact & Citation</h4>
              <p>For research inquiries and collaboration opportunities</p>
              <button onClick={handleCopyBibtex} className="citation-btn">
                üìã Copy BibTeX Citation
              </button>
            </div>
          </div>
          
          <div className="footer-bottom">
            <p>&copy; 2025 IndiCASA Research Team. This work is intended for academic research and educational purposes.</p>
            <p><strong>Content Warning:</strong> This research contains examples of harmful stereotypes for academic analysis.</p>
          </div>
        </div>
      </footer>
    </div>
  );
}

export default App;
