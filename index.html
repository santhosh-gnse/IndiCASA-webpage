<!doctype html><html lang="en"><head><meta charset="utf-8"/><link rel="icon" href="./favicon.png" type="image/png"/><link rel="icon" href="./favicon.ico" sizes="any"/><link rel="icon" href="./favicon.svg" type="image/svg+xml"/><link rel="apple-touch-icon" href="./favicon.png"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,user-scalable=yes"/><meta name="theme-color" content="#667eea"/><meta name="description" content="IndiCASA: A Dataset and Bias Evaluation Framework in LLMs Using Contrastive Embedding Similarity in the Indian Context. Research from IIT Madras and UT Dallas."/><meta name="keywords" content="AI bias, machine learning, Indian context, LLM evaluation, caste bias, gender bias, religious bias, disability bias, socioeconomic bias, contrastive learning, dataset, research"/><meta name="author" content="Centre for Responsible AI, IIT Madras"/><meta property="og:type" content="website"/><meta property="og:title" content="IndiCASA: AI Bias Evaluation Framework for Indian Contexts"/><meta property="og:description" content="A comprehensive dataset and evaluation framework for measuring bias in Large Language Models across Indian socio-cultural dimensions."/><meta property="og:url" content="https://indicasa-research.example.com"/><meta property="twitter:card" content="summary_large_image"/><meta property="twitter:title" content="IndiCASA: AI Bias Evaluation Framework"/><meta property="twitter:description" content="Advancing AI fairness through culturally-aware bias evaluation in Indian contexts."/><link rel="apple-touch-icon" href="/IndiCASA-webpage/logo192.png"/><link rel="manifest" href="/IndiCASA-webpage/manifest.json"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/><title>IndiCASA - AI Bias Evaluation Framework for Indian Contexts</title><script type="text/javascript">!function(n){if("/"===n.search[1]){var a=n.search.slice(1).split("&").map(function(n){return n.replace(/~and~/g,"&")}).join("?");window.history.replaceState(null,null,n.pathname.slice(0,-1)+a+n.hash)}}(window.location)</script><script defer="defer" src="/IndiCASA-webpage/static/js/main.35ed1d79.js"></script><link href="/IndiCASA-webpage/static/css/main.e6b90afd.css" rel="stylesheet"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id="root"></div><script type="application/ld+json">{
				"@context": "https://schema.org",
				"@type": "ResearchProject",
				"name": "IndiCASA: A Dataset and Bias Evaluation Framework in LLMs Using Contrastive Embedding Similarity in the Indian Context",
				"description": "A comprehensive research project evaluating bias in Large Language Models across Indian socio-cultural dimensions using advanced contrastive learning techniques.",
				"author": [
					{
						"@type": "Organization",
						"name": "Centre for Responsible AI, IIT Madras"
					},
					{
						"@type": "Organization",
						"name": "University of Texas at Dallas"
					}
				],
				"datePublished": "2025",
				"keywords": [
					"AI bias",
					"machine learning",
					"Indian context",
					"LLM evaluation",
					"contrastive learning"
				]
			}</script></body></html>